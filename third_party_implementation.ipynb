{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of logistic_regression_seldonian.ipynb","provenance":[{"file_id":"https://github.com/hannanabdul55/seldonian-fairness/blob/master/logistic_regression_seldonian.ipynb","timestamp":1620758068080}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"Tt71lpdHrF7k"},"source":["# Seldonian Model example usage notebook\n","This notebook shows the usage of the `seldonian` library to train a `LogisticRegression` classifier on the [UCI Adult Income Dataset](https://archive.ics.uci.edu/ml/datasets/adult)\n","\n","https://github.com/hannanabdul55/seldonian-fairness"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O7pzaBAUtbDq","executionInfo":{"status":"ok","timestamp":1620758107328,"user_tz":300,"elapsed":22641,"user":{"displayName":"Chenglu Li","photoUrl":"","userId":"04064632564695645091"}},"outputId":"51c6cc8a-7013-45fd-bd2f-aaf457fd0161"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hdWz82x7LuPa"},"source":["try:\n","    import seldonian\n","except:\n","    !pip install seldonian\n","import torch\n","import numpy as np\n","try:\n","    import shap\n","except:\n","    !pip install shap\n","\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score\n","\n","from seldonian.seldonian import *\n","from seldonian.objectives import ghat_tpr_diff, ghat_recall_rate, recall_rate, tpr_rate\n","from seldonian.bounds import ttest_bounds, hoeffdings_bounds"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"KM3g83dCrF7x"},"source":["# Dataset\n","We use the `shap` library to import the preprocessed version of the Adult data. "]},{"cell_type":"code","metadata":{"id":"miqDzE-GN1NV","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"ok","timestamp":1620764852678,"user_tz":300,"elapsed":10225,"user":{"displayName":"Chenglu Li","photoUrl":"","userId":"04064632564695645091"}},"outputId":"46f0bb1d-26c8-4bc4-fc20-ad3e622f7f44"},"source":["from sklearn import preprocessing\n","import pandas as pd\n","\n","df_assessments_agg_filtered = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Fair AI/algebra_nation/aggregated_assessments_v5.csv')\n","df_logs = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Fair AI/algebra_nation/logs.csv')\n","\n","# filtering\n","df_assessments_agg_filtered = df_assessments_agg_filtered[df_assessments_agg_filtered['is_finished'] == 1]\n","\n","# available_actions = df_logs['action_name'].dropna().unique()\n","available_actions = [\n","  'video_watch', 'video_pause', 'video_play', \n","  'video_seek', 'video_completed', \n","  'tys_review_correct_question', 'tys_review_solution_video', 'tys_review_topic_video',\n","  'wall_make_post', 'wall_search'\n","]\n","\n","df_assessments_agg_filtered['pass_status'] = \\\n","  (df_assessments_agg_filtered['num_correct_answer'] / df_assessments_agg_filtered['number_of_questions']) >= 0.7\n","\n","numeric_cols = []\n","numeric_cols = [f'{action} frequency' for action in available_actions]\n","# numeric_cols = [*numeric_cols, *[f'{action} duration' for action in available_actions]]\n","numeric_cols = ['history_avg_num_correct_answer', 'assessment_order', *numeric_cols]\n","\n","factor_cols = [\n","  'race',\n","  'gender',\n","  # 'grade',\n","  'subject_id', \n","  'school_id', \n","  # 'browser', 'os',\n","]\n","wanted_cols = [\n","  *factor_cols,\n","  *numeric_cols\n","]\n","\n","for col in factor_cols:\n","  if col == 'gender':\n","    df_assessments_agg_filtered[col] = df_assessments_agg_filtered[col].apply(lambda x: 1 if x == 'm' else 0)\n","  if col == 'race':\n","    df_assessments_agg_filtered[col] = df_assessments_agg_filtered[col].apply(lambda x: 1 if x == 'Black or African American' else 0)\n","  else:\n","    df_assessments_agg_filtered[col] = pd.factorize(df_assessments_agg_filtered[col])[0]\n","\n","df_assessments_agg_filtered[numeric_cols] = preprocessing.scale(df_assessments_agg_filtered[numeric_cols])\n","\n","df_assessments_agg_filtered['pass_status_factor'] = df_assessments_agg_filtered['pass_status'].apply(lambda x: 1 if x else 0)\n","\n","df_assessments_agg_filtered[[*wanted_cols, 'pass_status_factor']].head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>race</th>\n","      <th>gender</th>\n","      <th>subject_id</th>\n","      <th>school_id</th>\n","      <th>history_avg_num_correct_answer</th>\n","      <th>assessment_order</th>\n","      <th>video_watch frequency</th>\n","      <th>video_pause frequency</th>\n","      <th>video_play frequency</th>\n","      <th>video_seek frequency</th>\n","      <th>video_completed frequency</th>\n","      <th>tys_review_correct_question frequency</th>\n","      <th>tys_review_solution_video frequency</th>\n","      <th>tys_review_topic_video frequency</th>\n","      <th>wall_make_post frequency</th>\n","      <th>wall_search frequency</th>\n","      <th>pass_status_factor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-1.558706</td>\n","      <td>-0.664586</td>\n","      <td>-0.414555</td>\n","      <td>-0.429901</td>\n","      <td>-0.407606</td>\n","      <td>-0.470573</td>\n","      <td>-0.796654</td>\n","      <td>-0.176842</td>\n","      <td>-0.263111</td>\n","      <td>-0.382496</td>\n","      <td>-0.203514</td>\n","      <td>-0.13459</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.933318</td>\n","      <td>-0.603195</td>\n","      <td>-0.414555</td>\n","      <td>-0.429901</td>\n","      <td>-0.407606</td>\n","      <td>-0.470573</td>\n","      <td>-0.796654</td>\n","      <td>-0.176842</td>\n","      <td>-0.263111</td>\n","      <td>-0.382496</td>\n","      <td>-0.203514</td>\n","      <td>-0.13459</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.933318</td>\n","      <td>-0.541804</td>\n","      <td>-0.414555</td>\n","      <td>-0.429901</td>\n","      <td>-0.407606</td>\n","      <td>-0.470573</td>\n","      <td>-0.796654</td>\n","      <td>-0.176842</td>\n","      <td>-0.263111</td>\n","      <td>-0.382496</td>\n","      <td>-0.203514</td>\n","      <td>-0.13459</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.432179</td>\n","      <td>-0.480412</td>\n","      <td>-0.414555</td>\n","      <td>-0.429901</td>\n","      <td>-0.407606</td>\n","      <td>-0.470573</td>\n","      <td>-0.796654</td>\n","      <td>-0.176842</td>\n","      <td>-0.263111</td>\n","      <td>-0.382496</td>\n","      <td>-0.203514</td>\n","      <td>-0.13459</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.182749</td>\n","      <td>-0.419021</td>\n","      <td>-0.414555</td>\n","      <td>-0.429901</td>\n","      <td>-0.407606</td>\n","      <td>-0.470573</td>\n","      <td>-0.796654</td>\n","      <td>-0.176842</td>\n","      <td>-0.263111</td>\n","      <td>-0.382496</td>\n","      <td>-0.203514</td>\n","      <td>-0.13459</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   race  gender  ...  wall_search frequency  pass_status_factor\n","0     0       0  ...               -0.13459                   1\n","1     0       0  ...               -0.13459                   1\n","2     0       0  ...               -0.13459                   1\n","3     0       0  ...               -0.13459                   0\n","4     0       0  ...               -0.13459                   1\n","\n","[5 rows x 17 columns]"]},"metadata":{"tags":[]},"execution_count":162}]},{"cell_type":"markdown","metadata":{"id":"YHw-sOeqrF7x"},"source":["# Dataset statistics\n","Here, we plot the counts of each category of a column that you can specify in the cell below. This column will be used as the sensitive attribute in the rest of the notebook."]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"ZYzGIcqorF7y"},"source":["A = 'race'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"2QOcmvz_rF7y","colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"status":"ok","timestamp":1620763857157,"user_tz":300,"elapsed":658,"user":{"displayName":"Chenglu Li","photoUrl":"","userId":"04064632564695645091"}},"outputId":"d2f325b8-1f50-4642-f13d-52e7d1c9cd6c"},"source":["grps = df_assessments_agg_filtered.groupby(A)\n","counts = {}\n","for k,v in grps:\n","    counts[k] = v.shape[0]\n","plt.bar(counts.keys(), counts.values())\n","plt.title(f\"Counts of number of samples of each category in column {A}\")\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"ZMDGZeW6Hhzo"},"source":["class MyVanillaNN(SeldonianAlgorithm):\n","    \"\"\"\n","    Implement a Seldonian Algorithm on a Neural network.\n","    \"\"\"\n","\n","    def __init__(self, X, y, test_size=0.4, g_hats=[], verbose=False, stratify=False, epochs=10,\n","                 model=None, random_seed=0):\n","        \"\"\"\n","        Initialize a model with `g_hats` constraints. This class is an example of training a\n","        non-linear model like a neural network based on the Seldonian Approach.\n","        :param X: Input data, this also includes the safety set.\n","        :param y: targets for the data ``X``\n","        :param test_size: the fraction of ``X`` to be used for the safety test\n","        :param g_hats: a list of function callables that correspond to a constriant\n","        :param verbose: Set this to ``True`` to get some debug messages.\n","        :param stratify: set this to true if you want to do stratified sampling of safety set.\n","        :param epochs: number of epochs to run teh training of the model. Default: ``10``\n","        :param model: PyTorch model to use. Should be an instance of ``nn.Module``. Defaults to a 2 layer model with a binary output.\n","        \"\"\"\n","        self.X = X\n","        self.y = y\n","        D = self.X.shape[1]\n","        H1 = 128\n","        self.device = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","        print(f\"Running on {self.device}\")\n","        device = self.device\n","        self.constraint = g_hats\n","        self.verbose = verbose\n","        self.epochs = epochs\n","        # initialize the torch model using the Sequential API.\n","        if model is None:\n","            self.mod = nn.Sequential(\n","                nn.Linear(D, H1),\n","                nn.Linear(128, 64),\n","                nn.Linear(64, 32),\n","                nn.Linear(32, 16),\n","                nn.ReLU(),\n","                nn.Linear(16, 2)\n","            ).to(device)\n","        else:\n","            self.mod = model.to(device)\n","\n","        # Stratify the sampling method for safety and candidate set using the `stratify` param.\n","        if not stratify:\n","            self.X, self.X_s, self.y, self.y_s = train_test_split(\n","                self.X, self.y, test_size=test_size, random_state=random_seed\n","            )\n","            self.X = torch.as_tensor(self.X, dtype=torch.float, device=device)\n","            self.y = torch.as_tensor(self.y, dtype=torch.long, device=device)\n","            self.X_s = torch.as_tensor(self.X_s, dtype=torch.float, device=device)\n","            self.y_s = torch.as_tensor(self.y_s, dtype=torch.long, device=device)\n","        else:\n","            min_diff = np.inf\n","            count = 0\n","            self.X_t = self.X\n","            self.y_t = self.y\n","            while count < 30:\n","                self.X = self.X_t\n","                self.y = self.y_t\n","                self.X, self.X_s, self.y, self.y_s = train_test_split(\n","                    self.X, self.y, test_size=test_size,\n","                    random_state=count + 1\n","                )\n","                self.X = torch.as_tensor(self.X, dtype=torch.float, device=device)\n","                self.y = torch.as_tensor(self.y, dtype=torch.long, device=device)\n","                self.X_s = torch.as_tensor(self.X_s, dtype=torch.float, device=device)\n","                self.y_s = torch.as_tensor(self.y_s, dtype=torch.long, device=device)\n","                self.X_temp, self.X_s_temp, self.y_temp, self.y_s_temp = self.X, self.X_s, self.y, self.y_s\n","                if len(g_hats) > 0:\n","                    diff = abs(self._safetyTest(predict=True, ub=False) -\n","                               self._safetyTest(predict=False, ub=False))\n","                    if diff < min_diff:\n","                        self.X_temp, self.X_s_temp, self.y_temp, self.y_s_temp = self.X, self.X_s, self.y, self.y_s\n","                        min_diff = diff\n","                    count += 1\n","                else:\n","                    count += 30\n","            self.X, self.X_s, self.y, self.y_s = self.X_temp, self.X_s_temp, self.y_temp, self.y_s_temp\n","        self.loss_fn = nn.CrossEntropyLoss()\n","        # self.constraint = []\n","        if len(self.constraint) > 0:\n","            self.lagrange = torch.ones((len(self.constraint),), requires_grad=True, device=device)\n","        else:\n","            self.lagrange = None\n","\n","        self.dataset = torch.utils.data.TensorDataset(self.X, self.y)\n","        self.loader = DataLoader(self.dataset, batch_size=300)\n","        if self.lagrange is not None:\n","            params = nn.ParameterList(self.mod.parameters())\n","\n","            # optimizer used to train model parameters.\n","            self.optimizer = torch.optim.Adam(params, lr=6e-4)\n","\n","            # optimizer used for adjusting the lagrange multipliers\n","            self.l_optimizer = torch.optim.Adam([self.lagrange], lr=6e-3)\n","        else:\n","            # if it is an unconstrained problem, just init the model optimizer.\n","            self.optimizer = torch.optim.Adam(self.mod.parameters(), lr=3e-3)\n","            self.l_optimizer = None\n","        pass\n","\n","    def fit(self, **kwargs):\n","        running_loss = 0.0\n","        for epoch in range(self.epochs):\n","            for i, data in enumerate(self.loader, 0):\n","                x, y = data\n","                # print(x.shape, y.shape)\n","                self.optimizer.zero_grad()\n","                if self.l_optimizer is not None:\n","                    self.l_optimizer.zero_grad()\n","                out = self.mod(x)\n","                safety = self._safetyTest(predict=True)\n","                if self.lagrange is not None:\n","                    loss = self.loss_fn(out, y) + (self.lagrange ** 2).dot(\n","                        safety)\n","                else:\n","                    loss = self.loss_fn(out, y)\n","                loss.backward(retain_graph=True)\n","                # grad_check(self.mod.named_parameters())\n","                self.optimizer.step()\n","\n","                if self.l_optimizer is not None:\n","                    self.l_optimizer.zero_grad()\n","\n","                if self.lagrange is not None:\n","                    # loss_f = -1 * (self.loss_fn(self.mod(x), y) + (self.lagrange ** 2).dot(\n","                    #     self._safetyTest(predict=True)))\n","                    # loss_f.backward(retain_graph=True)\n","                    # # l_optimizer is a separate optimizer for the lagrangian.\n","                    # if self.l_optimizer is not None:\n","                    #     self.l_optimizer.step()\n","                    with torch.no_grad():\n","                        self.lagrange += 3e-3 * 2 * self.lagrange * safety\n","                    self.optimizer.zero_grad()\n","                running_loss += loss.item()\n","\n","                if i % 10 == 9:  # print every 2000 mini-batches\n","                    print('[%d, %5d] loss: %.3f' %\n","                          (epoch + 1, i + 1, running_loss / 10))\n","                    running_loss = 0.0\n","        print(\"Training done.\")\n","        pass\n","\n","    def predict(self, X, pmf=False, as_numpy=False):\n","        # print(f\"X is on device {X.get_device()}\")\n","        if not torch.is_tensor(X):\n","            X = torch.as_tensor(X, dtype=torch.float, device=self.device)\n","        elif X.get_device() is not self.device:\n","            X.to(self.device)\n","\n","        if not pmf:\n","            preds = torch.argmax(self.mod(X), dim=1)\n","        else:\n","            preds = nn.Softmax(dim=1)(self.mod(X))[:, 1]\n","\n","        if as_numpy:\n","          return preds.detach().cpu().numpy()\n","      \n","        return preds\n","\n","    def _safetyTest(self, predict=False, ub=True):\n","        with torch.no_grad():\n","            X_test = self.X if predict else self.X_s\n","            y_test = self.y if predict else self.y_s\n","\n","        ghats = torch.empty(len(self.constraint), device=self.device)\n","        i = 0\n","        for g_hat in self.constraint:\n","            y_preds = self.predict(X_test, False)\n","            ghats[i] = g_hat['fn'](X_test, y_test, y_preds, g_hat['delta'], self.X_s.shape[0],\n","                                   predict=predict, ub=ub)\n","            # ghats[i] = ghat_val\n","            i += 1\n","        if predict:\n","            return ghats\n","        else:\n","            return np.clip(np.mean(ghats.detach().cpu().numpy()), a_min=0, a_max=None)\n","\n","    def data(self):\n","        return self.X, self.y\n","\n","\n","def grad_check(named_params):\n","    avg = []\n","    for n, p in named_params:\n","        if p.requires_grad and (\"bias\" not in n):\n","            if p.grad is not None:\n","                avg.append(p.grad.abs().mean())\n","    print(f\"Average gradient flow: {np.mean(avg)}\")\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9U3Y3ATLrF70"},"source":["# Constraint definition\n","\n","In the Seldonian Approach, the safety constraints are defined as a tuple $(g_i, \\delta_i) \\forall i \\in m$ , where there are $m$ safety constraints.  $g: \\Theta \\to \\mathbb{R}$ is a function that quantifies the desirability of a solution and $\\delta$ is the permissive probability of returning an undesirable/unsafe solution.  \n","\n","Hence, if $f(\\theta, D)$ is the original minimization optimization objective where $D$ is the data, then the new Seldonian objective function is: \n","$$\\arg_{\\theta}\\min f(\\theta, D) \\quad \\quad \\quad \\text{s.t. } \\Pr(g_i(\\theta, D) \\le 0 ) \\ge 1- \\delta_i \\quad \\forall i \\in m  $$  \n","\n","The trianing is a 3 step-process: \n","- **Dataset split**: The input training data, $D$, is split into 2 sets - the candidate set, $D_{c}$, and the safety set, $D_{s}$.\n","- **Candidate selection** - This is the step executed when the `fit` method is called on the Seldonian Model. This method runs the optimization objective with the safety constraints using _only_ the data $D_c$. Since $D_s$ is not available at this step, we _predict_ the upper bound on $g(\\theta, D_s)$, let's call it $\\hat{g}(\\theta, D_c)$ using concentration inequalities like $ttest$ or _Hoeffding's_ bounds. \n","- **Safety test** - This step is used to run the trained parameters, $\\theta_c$ from the candidate selection step and calculate $g(\\theta_c, D_s)$.  \n","\n","Here we set `g_hats` as a list of $g(\\theta)$'s where each item is a dictionary with the `fn` key is assigned a function callable that calculates $g_i(\\theta)$ and the $\\delta_i$.  \n","\n","In this case, we have only one constraint which is the recall constraint on the `Sex` category in the dataset. This constraint is also known as `EqualizedOdds` constraint from [Hardt et.al 2016](https://proceedings.neurips.cc/paper/2016/file/9d2682367c3935defcb1f9e247a97c0d-Paper.pdf). The constraint is written as  \n","\n","$$g(\\theta) = |\\Pr(f(\\theta, X)=y |Y=y, A = Male) - \\Pr(f(\\theta, X)=y |Y=y, A = Female)| - 0.05 $$  \n","\n","where `X` is the input features, `A` is the sensitive feature (`Sex` in this case) and `Y` is the target/prediction. The `0.05` is the maximum value that is permissible.  \n","\n","Hence, this constraint upper bounds the absolute difference between the individual accuracy for each category of the sensitive attributes to `0.05`.  \n","\n","We also split the entire dataset to a trainj and test set. Note that the test set here is _different_ from the safety set used within the Seldonian Algorithm.\n"]},{"cell_type":"code","metadata":{"id":"FPv63xP858Nq"},"source":["# true positive rate rate should be equal for X[A=1] or X[A=0]\n","def ghat_eq_odds_rate(A_idx, method='ttest', threshold=0.2):\n","    \"\"\"\n","    Create a ``g_hat`` for the recall rate difference between :param A_idx subset versus\n","    the entire data.\n","    :param A_idx:\n","    :param method:\n","    :param threshold: Recall rate should not be greater than this value.\n","    :return: method that is to be sent to the Seldonian Algorithm and is used for calculating teh ``g_hat``\n","    \"\"\"\n","\n","    def eq_odds(X, y_true, y_pred, delta, n=None, predict=False, ub=True):\n","        recall_a = recall_rate(A_idx, 1)(X, y_true, y_pred)\n","        recall_b = recall_rate(A_idx, 0)(X, y_true, y_pred)\n","        tpr_a = tpr_rate(A_idx, 1)(X, y_true, y_pred)\n","        tpr_b = tpr_rate(A_idx, 0)(X, y_true, y_pred)\n","\n","        abs_fn = abs\n","        # if torch.is_tensor(X):\n","        #     abs_fn = torch.abs\n","\n","        if method == 'ttest':\n","            recall_diff = ttest_bounds(recall_b, delta, n, predict=predict) - ttest_bounds(recall_a, delta,\n","                                                                                 n,\n","                                                                                 predict=predict)\n","            tpr_diff = ttest_bounds(tpr_b, delta, n, predict=predict) - ttest_bounds(tpr_a, delta,\n","                                                                                 n,\n","                                                                                 predict=predict)\n","            if recall_diff.upper > tpr_diff.upper:\n","              bound = abs_fn(recall_diff)\n","            elif tpr_diff.upper > recall_diff.upper:\n","              bound = abs_fn(tpr_diff)\n","            else:\n","              bound = abs_fn(recall_diff)\n","        else:\n","            bound = abs_fn(\n","                hoeffdings_bounds(recall_b, delta, n, predict=predict) - hoeffdings_bounds(\n","                    recall_a, delta,\n","                    n,\n","                    predict=predict))\n","        if ub:\n","            return bound.upper - threshold\n","        else:\n","            return bound.value - threshold\n","\n","    return eq_odds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xQkSSHv-EBjm"},"source":["from sklearn.metrics import log_loss\n","\n","def loss_rate(A_idx=None, A_val=None):\n","    def _ghat_loss(X, y_true, y_pred):\n","        loss = []\n","        if A_idx is not None and A_val is not None:\n","            mask = X[:, A_idx] == A_val\n","            y_true = y_true[mask]\n","            y_pred = y_pred[mask]\n","\n","            for i in range(len(y_true)):\n","              loss.append(log_loss([y_true[i]], [y_pred[i]], labels=[0,1]))\n","        else:\n","            for i in range(len(y_true)):\n","              loss.append(log_loss([y_true[i]], [y_pred[i]], labels=[0,1]))\n","        return np.array(loss)\n","\n","    return _ghat_loss\n","\n","# true positive rate rate should be equal for X[A=1] or X[A=0]\n","def ghat_loss(A_idx, method='ttest', threshold=0.2):\n","    \"\"\"\n","    Create a ``g_hat`` for the recall rate difference between :param A_idx subset versus\n","    the entire data.\n","    :param A_idx:\n","    :param method:\n","    :param threshold: Recall rate should not be greater than this value.\n","    :return: method that is to be sent to the Seldonian Algorithm and is used for calculating teh ``g_hat``\n","    \"\"\"\n","\n","    def loss(X, y_true, y_pred, delta, n=None, predict=False, ub=True):\n","        loss_a = loss_rate(A_idx, 1)(X, y_true, y_pred)\n","        loss_b = loss_rate(A_idx, 0)(X, y_true, y_pred)\n","\n","        abs_fn = abs\n","\n","        if method == 'ttest':\n","            bound = ttest_bounds(np.array([*loss_b, *loss_a]), delta, n, predict=predict)\n","        else:\n","            bound = abs_fn(\n","                hoeffdings_bounds(recall_b, delta, n, predict=predict) - hoeffdings_bounds(\n","                    recall_a, delta,\n","                    n,\n","                    predict=predict))\n","        if ub:\n","            return bound.upper - threshold\n","        else:\n","            return bound.value - threshold\n","\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sZQ3yM1kMb0L"},"source":["X = df_assessments_agg_filtered[[*wanted_cols]]\n","Y = df_assessments_agg_filtered['pass_status_factor']\n","\n","EO_THRESHOLD = 0.1\n","LOSS_THRESHOLD = 0.1\n","\n","A_idx = list(X.columns).index(A)\n","X = X.to_numpy()\n","X_tr, X_te, y_tr,y_te = train_test_split(X, Y.to_numpy(), test_size=0.3, random_state=42)\n","g_hats = [\n","  {\n","    'fn': ghat_eq_odds_rate(A_idx, threshold=EO_THRESHOLD),\n","    'delta': 0.05\n","  },\n","  {\n","    'fn': ghat_loss(A_idx, threshold=LOSS_THRESHOLD),\n","    'delta': 0.05\n","  },\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0pIDxjIqrF72"},"source":["## Training the Seldonian Logistic Regression Model\n","The call to `model.fit()` run the candidate selection step and get the $\\theta_c$ parameter. "]},{"cell_type":"code","metadata":{"id":"QhRS04sDOb2U"},"source":["model = LogisticRegressionSeldonianModel(X_tr, y_tr, g_hats=g_hats, test_size=0.3, stratify=True)\n","model.fit()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WB_XvpZXrF72"},"source":["# Safety test\n","The call to `model._safetyTest()` runs the next step i.e.  the _safety test_ on the candidate model $\\theta_c$."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"komHZE_5Q0cm","executionInfo":{"status":"ok","timestamp":1620766099601,"user_tz":300,"elapsed":1678,"user":{"displayName":"Chenglu Li","photoUrl":"","userId":"04064632564695645091"}},"outputId":"10fa2fda-f391-4a9b-8d59-0b1e77e39aca"},"source":["safe = model._safetyTest()\n","print(f\"The trained model {'failed' if safe>0 else 'passed'} the safety test.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The trained model failed the safety test.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YnB54Mk3rF73"},"source":["# Seldonian Model metrics\n","Here, we report the Seldonian Model's accuracy and the violation i.e. the $g(\\theta_c)$ on the test set `X_te`. We can see that the $g(\\theta_c) < 0$. This means the candidate $\\theta_c$ _passed_ the safety test.  "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XbEkNNqhtMGc","executionInfo":{"status":"ok","timestamp":1620766222127,"user_tz":300,"elapsed":461,"user":{"displayName":"Chenglu Li","photoUrl":"","userId":"04064632564695645091"}},"outputId":"1a0bbb3a-b8c7-4cc2-cab1-f1242ccab984"},"source":["print(f\"Constrained model loss: {log_loss(y_te, model.predict(X_te))}\")\n","print(f\"Constrained model accuracy: {accuracy_score(y_te, model.predict(X_te))}\")\n","print(f\"Constrained model violation: {ghat_eq_odds_rate(A_idx, threshold=THRESHOLD)(X_te, y_te, model.predict(X_te), THRESHOLD, ub=False)} \")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Constrained model loss: 15.142188274381123\n","Constrained model accuracy: 0.5615966964900206\n","Constrained model violation: -0.04445128296236141 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2tZQFlYVrF74"},"source":["# Unconstrained model metrics\n","Now, we compare this model to an unconstrained model trained on the same dataset using scikit learns `LogisticRegression` and the same metrics are then calculated on the test set `X_te`. "]},{"cell_type":"code","metadata":{"id":"6_17W9SytQjg"},"source":["from sklearn.linear_model import LogisticRegression\n","\n","uc_model = LogisticRegression(solver='liblinear', random_state=42).fit(X_tr, y_tr)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uorjq29hrF75"},"source":["We can see that the unconstrained model _fails_ the safety test."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cKVy7eiLti5r","executionInfo":{"status":"ok","timestamp":1620763772597,"user_tz":300,"elapsed":399,"user":{"displayName":"Chenglu Li","photoUrl":"","userId":"04064632564695645091"}},"outputId":"ce124007-8cdb-4341-ebec-c182253e9727"},"source":["g_theta_test = ghat_eq_odds_rate(A_idx, threshold=THRESHOLD)(X_te, y_te, uc_model.predict(X_te), THRESHOLD, ub=False)\n","print(f\"Uncontrained model accuracy: {accuracy_score(y_te, uc_model.predict(X_te))}\")\n","print(f\"Unconstrained model value of g(\\\\theta): {g_theta_test}\")\n","print(f\"Hence, this model {'failed' if g_theta_test >0 else 'passed'} the safety test\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Uncontrained model accuracy: 0.7543014452856159\n","Unconstrained model value of g(\\theta): 0.03554668663231898\n","Hence, this model failed the safety test\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HAc_n01vv-cm"},"source":[""],"execution_count":null,"outputs":[]}]}